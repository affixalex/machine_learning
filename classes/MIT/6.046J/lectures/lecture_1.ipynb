{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Algorithms\n",
    "\n",
    "The theoretical study of computer program resource usage and **performance**.\n",
    "\n",
    "Before you can do design, you have to master a bunch of techniques for analyzing algorithms. Then you'll be in a position to create algorithms which will be efficient. We're studying how to make things *fast*.\n",
    "\n",
    "## What is more important than performance?\n",
    "\n",
    "1. Correctness\n",
    "2. Simplicity\n",
    "3. Maintainability\n",
    "4. Robustness\n",
    "5. Cost\n",
    "6. Features\n",
    "7. Modularity\n",
    "8. Security\n",
    "9. Usability\n",
    "\n",
    "## So why study algorithms and performance?\n",
    "\n",
    "Sometimes performance is correlated with usability. Programs with realtime constraints don't actually work unless they perform adequately.\n",
    "\n",
    "Often, performance is the line between feasible and infeasible. Citing the realtime example again, if it's not fast enough it just doesn't work. As a consequence, algorithms are on the cutting edge of entrepreneurship. If you're talking about things that haven't been done before, resource constraints and performance are often the reason it hasn't.\n",
    "\n",
    "Performance is like currency. What good does a stack of 100 dollar bills do for you? Wouldn't you rather have food or water or shelter or whatever? You're willing to trade the money for that commodity. Similarly, performance is what you use to pay for user friendliness and security.\n",
    "\n",
    "Lastly, it's fun!\n",
    "\n",
    "## Insertion Sorting\n",
    "\n",
    "Sorting contains many algorithmic techniques.\n",
    "\n",
    "Given a sequence $a1,a2,a3,...,aN$ our output is a permutation of those numbers. A permutation is a rearrangement of the numbers such that $a1\\le a2\\prime$ such that they are monotonically increasing in size and every number appears exactly once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 17, 20, 26, 31, 44, 54, 55, 77, 93, 99]\n"
     ]
    }
   ],
   "source": [
    "def insertionSort(alist):\n",
    "    for index in range(1,len(alist)): # Begin at 1 to compare items 0 and 1.\n",
    "        currentvalue = alist[index] # Then, we grab the value at this index.\n",
    "        position = index # This is our \"key\", hopefully everything before this is sorted\n",
    "\n",
    "        # Now, beginning at `position` we look back and try to figure out where to \n",
    "        # insert the current value. \n",
    "        while position>0 and alist[position-1]>currentvalue:\n",
    "            alist[position]=alist[position-1]\n",
    "            position = position-1\n",
    "        \n",
    "        # This is where insertion sort gets the name.\n",
    "        alist[position]=currentvalue\n",
    "\n",
    "    \n",
    "alist = [54,26,93,17,99,77,31,44,55,20,1]\n",
    "insertionSort(alist)\n",
    "print(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Depends on input\n",
    "\n",
    "Is it already sorted? If the input is reverse sorted, then obviously the running time will be longer. \n",
    "\n",
    "### 2.) Depends on size\n",
    "\n",
    "Here we did $11$ elements. $11 * 10^9$ elements would take much longer.\n",
    "\n",
    "We want to **paramaterize the input size**. We want to know the upper bounds of runtime. In other words, we want to know that the runtime is no more than a certain amount. The reason is that **this represents a guarantee to the user**. \n",
    "\n",
    "### Kinds of Analysis\n",
    "\n",
    "#### Worst Case Analysis (usually)\n",
    "\n",
    "This is where we define $(T)n$ to be the maximum running time on any input of size $n$.\n",
    "\n",
    "#### Average Case Analysis (sometimes)\n",
    "\n",
    "Here, $T(n)$ is then the *expected* running time for all inputs of size $n$.\n",
    "\n",
    "What does this mean? Take the time of every input and then average them? Good, but not quite.\n",
    "\n",
    "We want a weighted average. Take the time of every input and the *probability* of that input.\n",
    "\n",
    "This requires an assumption of the statistical distribution of inputs. Otherwise, an average time doesn't mean anything. One of the most common assumptions is the uniform distribution - every input of size $n$ is equally likely. This is much more complicated.\n",
    "\n",
    "#### Best Case Analysis (bogus)\n",
    "\n",
    "Easy to cheat with a slow algorithm that works fast on some input. \n",
    "\n",
    "### What is insertion sort's worst case time?\n",
    "\n",
    "1. Depends on computer\n",
    "    1. Relative speed (on same machine)\n",
    "    2. Absolute speed (on different machines)\n",
    "    \n",
    "So this is confusing. \n",
    "    \n",
    "### BIG IDEA! Asymptotic Analysis\n",
    "\n",
    "1. Ignore machine dependent constants\n",
    "2. Ignore running time\n",
    "3. Look at **GROWTH** of $T(n)$ as $n \\to \\infty$\n",
    "\n",
    "What do we mean by this? It's a huge idea... not a hard idea, but a huge one. In order to do this, we'll adopt some notations to help us. **Asymptotic notation**. The one we're going to be using in this class predominantly is **$\\theta$ (theta) notation**. \n",
    "\n",
    "The idea is, you drop low order terms and ignore leading constants. \n",
    "\n",
    "#### Example\n",
    "\n",
    "$$3n^3 + 90n^2 - 5n + 6046 =$$\n",
    "\n",
    "What low order terms do I drop? Well, $n^3$ is a bigger term than $n^2$ so this is pretty easy.\n",
    "\n",
    "$$3n^3 + 90n^2 - 5n + 6046 = \\theta n^3$$\n",
    "\n",
    "This is an engineering way of manipulating theta notation. There is also a mathematical way... thinking in terms of sets of functions. We'll be using both in this course.\n",
    "\n",
    "As $n \\to \\infty$ a $\\theta n^2$ algorithm always beats a $\\theta n^3$ algorithm. It doesn't matter what the lower order terms or leading constants are.\n",
    "\n",
    "# RESUME NOTES AT 54 MINUTES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
